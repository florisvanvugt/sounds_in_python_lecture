{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello! I am Floris.\n",
    "\n",
    "https://www.florisvanvugt.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Open for questions at any time. Love interruptions. What matters is that you can follow along.\n",
    "\n",
    "* Let's take regular breaks. Body movement is important. If you feel you need to move, please tell me. That's not lazy, that's taking care of your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bureaucratics\n",
    "%pylab inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import Audio, Image, Video, display, clear_output\n",
    "from IPython.core.display import HTML \n",
    "import scipy.io.wavfile\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also you will need sound files (see Github repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating a simple sound wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='music_everywhere.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What are properties of sounds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The simplest sounds are pure tones: air pressure is a sine wave function of time.\n",
    "* The frequency of this sine wave determines the pitch of the sound (how high it sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple sine wave sound of a frequency of 440 Hz.\n",
    "# I won't explain the details of this right now, just to get us started!\n",
    "f = 440\n",
    "SR = 44100\n",
    "t = arange(0,1,1/SR)\n",
    "signal = np.sin(2*pi*f*t)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the above code, we need to understand something about how computers represent sounds.\n",
    "\n",
    "* Sound waves are continuous. There is a particular air pressure at every moment in time which is just a little different from every other moment in time.\n",
    "* However computers cannot deal with continuous signals that well. So instead we approximate the sound wave by a set of measurements at different points in time.\n",
    "* We refer to these measurements as **samples**, and the rate by which they occur in time as the **sampling rate** (samples per time). Typically that's a very high number, like 44100 per second, i.e. 44.1 kHz.\n",
    "* The higher the sampling rate, the more it will approximate the real, continuous sound wave. The better it will sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='reconstructing-the-original-signal.jpeg') ## source: https://www.izotope.com/en/learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine at what times we will take a sample, we make a list of time points using `arange`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of using arange(from,to,step) (you have it in Matlab too I think)\n",
    "arange(0,100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arange(0,1,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now back to our example:\n",
    "SR = 100 # very low!\n",
    "t = arange(0,1,1/SR)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now back to our example:\n",
    "SR = 44100 # more typical\n",
    "t = arange(0,1,1/SR)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling rate typically is expressed in Hz, which is number/second.\n",
    "\n",
    "A sampling rate of 44100 means 44100 samples per second. We also often write 44.1 kHz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the time vector we can create the desired air pressure signal.\n",
    "\n",
    "**Frequency** of a sound is the number of cycles per unit of time.\n",
    "\n",
    "For example, the number of \"waves\" during 1 second. Expressed in Hz again.\n",
    "\n",
    "There is a formula:\n",
    "    \n",
    "$$\\textrm{signal}=\\sin(2\\pi*f*t)$$\n",
    "\n",
    "Where $t$ is time, and $f$ is the frequency (in \"cycles\" per time).\n",
    "\n",
    "We use the `numpy.sin()` function to calculate the sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.sin(2*pi*f*t)\n",
    "signal[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are called **samples**, and the rate at which they occur is the **sampling rate** (taux d'Ã©chantillonnage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(signal[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "#SR = 2000\n",
    "#SR = 950\n",
    "#SR = 800\n",
    "#SR = 700\n",
    "f = 440\n",
    "t = arange(0,1,1/SR)\n",
    "signal = np.sin(2*pi*f*t)\n",
    "\n",
    "plot(t,signal)\n",
    "xlim(0,.005)\n",
    "\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advanced\n",
    "\n",
    "SRs = [44100,2000,800,700]\n",
    "\n",
    "f = 440\n",
    "\n",
    "t_hires = arange(0,1,1/max(SRs))\n",
    "s_hires = np.sin(2*pi*f*t_hires)\n",
    "\n",
    "fig,axs = subplots(len(SRs),1,sharex=True,figsize=(8,8))\n",
    "for ax,SR in zip(axs,SRs):\n",
    "    t = arange(0,1,1/SR)\n",
    "    signal = np.sin(2*pi*f*t)\n",
    "    ax.plot(t_hires,s_hires,color='gray')\n",
    "    ax.plot(t,signal,'o-',color='blue')\n",
    "    ax.set_xlim(0,.005)\n",
    "    ax.set_title(\"rate = %.0f Hz\"%SR)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary so far\n",
    "\n",
    "* Sound waves are variations in air pressure over time.\n",
    "* The simplest sounds are pure tones, where air pressure is a sine wave function of time.\n",
    "* Although sound waves are continuous, we measure them in discrete samples, at a particular sampling rate (samples per time)\n",
    "* The higher the sampling rate, the more fidelity (being truthful to the original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pitch** refers to the *perceptual* quality that some sounds are higher and some lower. This perceptual quality corresponds to the physical property of frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/qNf9nzvnd1k?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to WAVE file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy.io.wavfile.write(filename, rate, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't you just love the internet? https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write('a440.wav',SR,signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,dt = scipy.io.wavfile.read('a440.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dt[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude\n",
    "\n",
    "What makes some sounds louder than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_nonorm_unit(data,rate):\n",
    "    # I'll tell you later what these two commands are doing here:\n",
    "    dat = array(data) # ensure editable\n",
    "    dat[-1]=1    # disable normalization for signal [-1,1]\n",
    "    display(Audio(data=dat, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 440\n",
    "t = arange(0,1,1/SR)\n",
    "signal = .5 * np.sin(2*pi*f*t) # modify amplitude\n",
    "play_nonorm_unit(signal,SR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amplitude** can be thought of as the difference between the maximum and the minimum value of the signal.\n",
    "\n",
    "The greater the amplitude, the greater the changes in air pressure, and the louder the sound. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary so far\n",
    "\n",
    "* The **frequency** of a sound corresponds to its perceived pitch.\n",
    "* The **amplitude** of a sound corresponds to its perceived loudness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic sound editing issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Fading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this click at the beginning and end annoy you too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 342.1\n",
    "SR = 44100\n",
    "t = linspace(0,1,SR)\n",
    "signal = np.sin(2*pi*f*t)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(signal[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a cliffhanger!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What can we do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fading! That is, changing the amplitude of the sound gradually from zero to full at the beginning, and then back from full to zero at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fade in the entire sound first (easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fader = linspace(0,1,SR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermezzo: `linspace(from,to,n)` (Ã  ne pas confondre avec `arange()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linspace(0,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linspace(0,10,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsignal = fader*signal\n",
    "display(Audio(data=newsignal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(newsignal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you instead fade out the sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we want to fade in, then plateau, and then fade out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_fade = int(.1*SR)\n",
    "n_samples_plateau = int(.8*SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fade_in  = linspace(0,1,n_samples_fade)\n",
    "plateau  = ones(n_samples_plateau)\n",
    "fade_out = linspace(1,0,n_samples_fade)\n",
    "\n",
    "envelope = concatenate([fade_in,plateau,fade_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsignal = envelope*signal\n",
    "display(Audio(data=newsignal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(newsignal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you make the fade take longer, i.e. 200ms instead of 100ms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Volume normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sound source: freesound.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_nonorm(data,rate):\n",
    "    # I'll tell you later what these two commands are doing here:\n",
    "    dat = array(data) # ensure editable\n",
    "    dat[-1]=32767    # disable normalization\n",
    "    display(Audio(data=dat, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,sneeze = scipy.io.wavfile.read('sneeze.wav') \n",
    "## reading a wave sound gives you two variables, the first is the sampling rate,\n",
    "## and the second is the actual sound data.\n",
    "play_nonorm(sneeze,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,whisper = scipy.io.wavfile.read('whisper.wav')\n",
    "play_nonorm(whisper,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sneeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze.shape # that many samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you create a time vector to go with the signal? You know the signal sampling rate, you know how many samples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sneeze.shape[0]\n",
    "t = arange(n)/rt # create a corresponding time vector\n",
    "# arange(n) is short for arange(0,n,1)\n",
    "plot(t,sneeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's plot them together. What do you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = arange(0,sneeze.shape[0])/rt # create a corresponding time vector\n",
    "plot(t,sneeze)\n",
    "t2 = arange(0,whisper.shape[0])/rt # create a corresponding time vector\n",
    "plot(t2,whisper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How can we make the volume more similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(5*whisper,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but can we be a bit more systematic about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Peak normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way: take the maximum and make it the same across both sounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you rescale the amplitude of the sneeze so that its maximum is 30000? (yes that's an arbitrary number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneezenorm = 30000*(sneeze/max(sneeze))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sneezenorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(sneezenorm,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whispernorm = 30000*(whisper/max(whisper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(whispernorm,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is the limitation of using peak normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 RMS normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea: take the square, then take the mean, then take the root of the signal. You should get one value.\n",
    "\n",
    "RMS square -> mean -> root\n",
    "\n",
    "mathematically: root(mean(square(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy example: [2,1,0,1,2] \n",
    "What is the RMS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squares: 4,1,0,1,4, mean = 10/5=2, sqrt = sqrt(2)~1.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array([2,1,0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean(x**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with real sounds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze = array(sneeze,dtype=float32) # don't worry about why this is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power(sneeze,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(power(sneeze,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean(power(sneeze,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper = array(whisper,dtype=float32) # don't worry about why this is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean(power(whisper,2))) # what do you expect about the value that you'll get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze_rms = sneeze/ sqrt(mean(power(sneeze,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_rms = whisper/ sqrt(mean(power(whisper,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sneeze_rms)\n",
    "plot(whisper_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(whisper_rms,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: WTF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah right, we normalized both sounds to a really really weak volume!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(30000*whisper_rms,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(30000*sneeze_rms,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Sounds coming together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_nonorm(15000*(whisper_rms+sneeze_rms),rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Musical chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "f1 = 440\n",
    "f2 = 660\n",
    "t = arange(0,1,1/SR)\n",
    "signal = np.sin(2*pi*f1*t)+np.sin(2*pi*f2*t)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t,signal); xlim(0,.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 3\n",
    "def two_frequencies(f1=220.0, f2=224.0):\n",
    "    t = arange(0,duration,1/SR)\n",
    "    signal = np.sin(2*np.pi*f1*t) + np.sin(2*np.pi*f2*t)\n",
    "    display(Audio(data=signal, rate=SR))\n",
    "    return signal\n",
    "\n",
    "v = interactive(two_frequencies, f1=(200.0,300.0), f2=(200.0,300.0))\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Musical sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to present sounds one after another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 440\n",
    "f2 = 660\n",
    "t = arange(0,1,1/SR)\n",
    "sound1 = np.sin(2*pi*f1*t)\n",
    "sound2 = np.sin(2*pi*f2*t)\n",
    "signal = concatenate([sound1,sound2])\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "t = arange(0,1,1/SR)\n",
    "for f in [440,550,660,880,660,550,440]:\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds.append(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = concatenate(sounds)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**: can you allow as part of the loop to have sounds of different durations as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "for f,dur,sil in [\n",
    "    (264,.250,.5),\n",
    "    (264,.250,.25),\n",
    "    (297,1,.25),\n",
    "    (264,1,.25),\n",
    "    (352,1,.25),\n",
    "    (330,2,.5)]:\n",
    "    t = arange(0,dur,1/SR)\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds.append(sound)\n",
    "    sounds.append(zeros(int(sil*SR)))\n",
    "signal = concatenate(sounds)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Forever rising..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we have sounds that go on rising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step: create all octaves (= doubling of frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = arange(0,1,1/SR)\n",
    "sounds = zeros(1*SR)\n",
    "for f in [110, 220, 440, 880, 1760, 3520, 7040, 14080, 28160, 56320, 112640]:\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds += sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=sounds, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical hearing of humans is from 20 Hz to 20 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 20\n",
    "f*(2**arange(11)) # roughly the frequencies we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basef = 20\n",
    "t = linspace(0,1,SR)\n",
    "sounds = zeros(1*SR)\n",
    "for f in basef*(2**arange(11)):\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds += sound\n",
    "display(Audio(data=sounds, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Wrap that in a function that takes base frequency as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alloctaves(basef,dur=1):\n",
    "    # Create a sound that contains lots of octaves above and below\n",
    "    # a certain base frequency (basef) and that lasts dur seconds\n",
    "    t = arange(0,dur,1/SR)\n",
    "    sounds = zeros(int(dur*SR))\n",
    "    for f in basef*(2**arange(11)):\n",
    "        sound = np.sin(2*pi*f*t)\n",
    "        sounds += sound\n",
    "    return sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=alloctaves(23), rate=SR)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispoct(f):\n",
    "    display(Audio(data=alloctaves(f), rate=SR)) \n",
    "v = interactive(dispoct, f=(20,40))\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you make a sequence of three shepard tones with base frequencies 20, 21 and 22 Hz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "for f in range(20,40,1):\n",
    "    sound = alloctaves(f,.25)\n",
    "    sounds.append(sound)\n",
    "    sounds.append(zeros(int(.05*SR)))\n",
    "signal = concatenate(sounds)\n",
    "signal = concatenate([signal,signal,signal,signal])\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Shepard tones! https://en.wikipedia.org/wiki/Shepard_tone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = alloctaves(20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we find what frequencies were part of this sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's where Fourier analysis comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Transform allows us to write any signal as a combination of pure sine waves. So it's doing the inverse of what we've been doing so far, namely combining pure sound waves into more complex sounds.\n",
    "\n",
    "The human ear also does something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"2---Cochlear animation.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://4d6619e6-a-62cb3a1a-s-sites.googlegroups.com/site/jayanthinyswebsite/workshops/different%20aspects%20of%20organ%20of%20Corti.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bunch of detail in terms of math that is not too important here. What is important is the idea that you have a signal, and then it splits it into the various frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourierTransform = np.fft.fft(sound)/len(sound)           # Normalize amplitude\n",
    "fourierTransform = fourierTransform[range(int(len(sound)/2))] # Exclude sampling frequency\n",
    "tpCount     = len(sound)\n",
    "values      = np.arange(int(tpCount/2))\n",
    "timePeriod  = tpCount/SR\n",
    "frequencies = values/timePeriod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(frequencies, abs(fourierTransform))\n",
    "xlim(0,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the amplitude too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 440\n",
    "f2 = 660\n",
    "t = arange(0,1,1/SR)\n",
    "sound = np.sin(2*pi*f1*t)+.5*np.sin(2*pi*f2*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourierTransform = np.fft.fft(sound)/len(sound)           # Normalize amplitude\n",
    "fourierTransform = fourierTransform[range(int(len(sound)/2))] # Exclude sampling frequency\n",
    "tpCount     = len(sound)\n",
    "values      = np.arange(int(tpCount/2))\n",
    "timePeriod  = tpCount/SR\n",
    "frequencies = values/timePeriod\n",
    "plot(frequencies, abs(fourierTransform))\n",
    "xlim(400,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://www.nti-audio.com/portals/0/pic/news/FFT-Time-Frequency-View-540.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "for f in [440,550,660,880,660,550,440]:\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds.append(sound)\n",
    "data = concatenate(sounds)\n",
    "#signal = concatenate([signal])\n",
    "display(Audio(data=data, rate=SR))\n",
    "\n",
    "specgram(data,Fs=SR) \n",
    "ylabel('Frequency [Hz]')\n",
    "xlabel('Time [sec]')\n",
    "ylim(0,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,data = scipy.io.wavfile.read('youare.wav') # source https://www.101soundboards.com\n",
    "display(Audio(data=data, rate=rt))\n",
    "specgram(data,Fs=rt) \n",
    "ylabel('Frequency [Hz]')\n",
    "xlabel('Time [sec]')\n",
    "ylim(0,15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Simple experiment: mapping positions to sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "van Vugt & Ostry \"audiomotor\" paradigm.\n",
    "\n",
    "http://www.psych.mcgill.ca/labs/mcl/pdf/jocn_a_01204.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://pbs.twimg.com/media/EHFzGNGXkAEzcv2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simplified mapping between position and sound:\n",
    "def angle2sound(angle):\n",
    "    # Angle in degrees, between 0 and 180 degrees\n",
    "    f1 = 400+2*angle\n",
    "    f2 = 1600-2*angle\n",
    "    sound = np.sin(2*pi*f1*t)+np.sin(2*pi*f2*t)\n",
    "    return sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=angle2sound(0),rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an interface\n",
    "\n",
    "Buttons, sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_next = ipywidgets.Button(description=\"Choose next target\")\n",
    "response = ipywidgets.IntSlider(value=90,min=0,max=180,step=1,\n",
    "                                description='What angle do you think corresponds to that sound?')\n",
    "button_respond = ipywidgets.Button(description=\"Select response\")\n",
    "display(button_next,response,button_respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {}\n",
    "record[\"target_angle\"] = 180*random.random()\n",
    "\n",
    "def select_target(e):\n",
    "    snd = angle2sound(record[\"target_angle\"])\n",
    "    clear_output()\n",
    "    display(ipywidgets.Label(value=\"This is your target sound:\"))\n",
    "    display(Audio(data=snd,rate=SR))\n",
    "    # add buttons for responding\n",
    "    display(response)\n",
    "    display(button_respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_next.on_click(select_target)\n",
    "display(button_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_response(e):\n",
    "    val = response.value\n",
    "    # Give the feedback sound\n",
    "    snd = angle2sound(val)\n",
    "    clear_output()\n",
    "    display(ipywidgets.Label(value=\"This is your feedback sound for an angle of \"+str(val)))\n",
    "    display(Audio(data=snd,rate=SR))\n",
    "    display(button_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_respond.on_click(register_response)\n",
    "display(button_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But so far we don't keep a record of the subject's performance.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {'trials':[]}\n",
    "record[\"target_angle\"] = 180*random.random()\n",
    "\n",
    "def register_response(e):\n",
    "    val = response.value\n",
    "    record[\"trials\"].append({'target_angle':record[\"target_angle\"],\n",
    "                            'response_angle':val})\n",
    "    # Give the feedback sound\n",
    "    snd = angle2sound(val)\n",
    "    clear_output()\n",
    "    display(ipywidgets.Label(value=\"This is your feedback sound for an angle of \"+str(val)))\n",
    "    display(Audio(data=snd,rate=SR))\n",
    "    display(button_next)\n",
    "    \n",
    "button_respond.on_click(register_response)\n",
    "display(button_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record[\"trials\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = record['trials']\n",
    "for trial in trials:\n",
    "    trial['error']=trial['target_angle']-trial['response_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ trial['error'] for trial in trials ]\n",
    "plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's all folks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
