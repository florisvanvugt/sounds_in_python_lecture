{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello! I am Floris.\n",
    "\n",
    "https://www.florisvanvugt.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bureaucratics\n",
    "%pylab inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import Audio, display\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.display import HTML \n",
    "import scipy.io.wavfile\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also you will need sound files (see Github repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating a simple sound wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What are properties of sounds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a simple sound wave, a pure sound at 440 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 440\n",
    "t = linspace(0,1,44100)\n",
    "signal = np.sin(2*pi*f*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=signal, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are called **samples**, and the rate at which they occur is the **sampling rate** (taux d'Ã©chantillonnage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling rate typically is expressed in Hz, which is number/second.\n",
    "\n",
    "A sampling rate of 44100 means 44100 samples per second. We also often write 44.1 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t,signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t,signal)\n",
    "xlim(0,.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t,signal,'o')\n",
    "xlim(0,.001)\n",
    "# so we see the samples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What will happen if we multiply the signal by .5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amplitude** can be thought of as the difference between the maximum and the minimum value of the signal.\n",
    "\n",
    "The greater the amplitude, the louder the sound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What determines the pitch of a sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequency** of a sound is the number of cycles per unit of time.\n",
    "\n",
    "For example, the number of \"waves\" during 1 second. Expressed in Hz again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a formula:\n",
    "    \n",
    "$$\\textrm{signal}=\\sin(2\\pi*f*t)$$\n",
    "\n",
    "Where $t$ is time, and $f$ is the frequency (in periods per time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 440\n",
    "SR = 44100\n",
    "t = linspace(0,1,SR)\n",
    "signal = np.sin(2*pi*f*t)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to WAVE file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy.io.wavfile.write(filename, rate, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't you just love the internet? https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write('a440.wav',SR,signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,dt = scipy.io.wavfile.read('a440.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dt[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic sound editing issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Fading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this annoy you too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 342.1\n",
    "SR = 44100\n",
    "t = linspace(0,1,SR)\n",
    "signal = np.sin(2*pi*f*t)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(signal[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a cliffhanger!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What can we do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fade in the entire sound first (easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fader = linspace(0,1,SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsignal = fader*signal\n",
    "display(Audio(data=newsignal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(newsignal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you instead fade out the sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we want to fade in, then plateau, and then fade out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_fade = int(.1*SR)\n",
    "n_samples_plateau = int(.8*SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fade_in  = linspace(0,1,n_samples_fade)\n",
    "plateau  = ones(n_samples_plateau)\n",
    "fade_out = linspace(1,0,n_samples_fade)\n",
    "\n",
    "envelope = concatenate([fade_in,plateau,fade_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsignal = envelope*signal\n",
    "display(Audio(data=newsignal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(newsignal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you make the fade take longer, i.e. 200ms instead of 100ms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Volume normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sound source: freesound.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_nonorm(data,rate):\n",
    "    # I'll tell you later what these two commands are doing here:\n",
    "    dat = array(data) # ensure editable\n",
    "    dat[-1]=32767    # disable normalization\n",
    "    display(Audio(data=dat, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,sneeze = scipy.io.wavfile.read('sneeze.wav')\n",
    "play_nonorm(sneeze,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,whisper = scipy.io.wavfile.read('whisper.wav')\n",
    "play_nonorm(whisper,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sneeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze.shape # that many samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you create a time vector to go with the signal? You know the signal sampling rate, you know how many samples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = sneeze.shape[0]\n",
    "t = arange(0,sneeze.shape[0])/rt # create a corresponding time vector\n",
    "plot(t,sneeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's plot them together. What do you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = arange(0,sneeze.shape[0])/rt # create a corresponding time vector\n",
    "plot(t,sneeze)\n",
    "t2 = arange(0,whisper.shape[0])/rt # create a corresponding time vector\n",
    "plot(t2,whisper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How can we make the volume more similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(5*whisper,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but can we be a bit more systematic about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Peak normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way: take the maximum and make it the same across both sounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you rescale the amplitude of the sneeze so that its maximum is 30000? (yes that's an arbitrary number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneezenorm = 30000*(sneeze/max(sneeze))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sneezenorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(sneezenorm,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whispernorm = 30000*(whisper/max(whisper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(whispernorm,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What is the limitation of using peak normalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 RMS normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea: take the square, then take the mean, then take the root of the signal. You should get one value.\n",
    "\n",
    "RMS square -> mean -> root\n",
    "\n",
    "mathematically: root(mean(square(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy example: [2,1,0,1,2] \n",
    "What is the RMS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squares: 4,1,0,1,4, mean = 10/5=2, sqrt = sqrt(2)~1.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array([2,1,0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean(x**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with real sounds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze = array(sneeze,dtype=float32) # don't worry about why this is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power(sneeze,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(power(sneeze,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean(power(sneeze,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper = array(whisper,dtype=float32) # don't worry about why this is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean(power(whisper,2))) # what do you expect about the value that you'll get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneeze_rms = sneeze/ sqrt(mean(power(sneeze,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_rms = whisper/ sqrt(mean(power(whisper,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sneeze_rms)\n",
    "plot(whisper_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(whisper_rms,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: WTF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah right, we normalized both sounds to a really really weak volume!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(30000*whisper_rms,rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_nonorm(30000*sneeze_rms,rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Sounds coming together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_nonorm(15000*(whisper_rms+sneeze_rms),rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Musical chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "f1 = 440\n",
    "f2 = 660\n",
    "t = linspace(0,1,SR)\n",
    "signal = np.sin(2*pi*f1*t)+np.sin(2*pi*f2*t)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t,signal); xlim(0,.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 3\n",
    "def two_frequencies(f1=220.0, f2=224.0):\n",
    "    t = np.linspace(0,duration,SR*duration)\n",
    "    signal = np.sin(2*np.pi*f1*t) + np.sin(2*np.pi*f2*t)\n",
    "    display(Audio(data=signal, rate=SR))\n",
    "    return signal\n",
    "\n",
    "v = interactive(two_frequencies, f1=(200.0,300.0), f2=(200.0,300.0))\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Musical sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to present sounds one after another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 440\n",
    "f2 = 660\n",
    "t = linspace(0,1,SR)\n",
    "sound1 = np.sin(2*pi*f1*t)\n",
    "sound2 = np.sin(2*pi*f2*t)\n",
    "signal = concatenate([sound1,sound2])\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "t = linspace(0,1,SR)\n",
    "for f in [440,550,660,880,660,550,440]:\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds.append(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = concatenate(sounds)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**: can you allow as part of the loop to have sounds of different durations as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "for f,dur,sil in [\n",
    "    (264,.250,.5),\n",
    "    (264,.250,.25),\n",
    "    (297,1,.25),\n",
    "    (264,1,.25),\n",
    "    (352,1,.25),\n",
    "    (330,2,.5)]:\n",
    "    t = linspace(0,dur,int(dur*SR))\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds.append(sound)\n",
    "    sounds.append(zeros(int(sil*SR)))\n",
    "signal = concatenate(sounds)\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Forever rising..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we have sounds that go on rising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step: create all octaves (= doubling of frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = linspace(0,1,SR)\n",
    "sounds = zeros(1*SR)\n",
    "for f in [110, 220, 440, 880, 1760, 3520, 7040, 14080, 28160, 56320, 112640]:\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds += sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=sounds, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical hearing of humans is from 20 Hz to 20 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 20\n",
    "f*(2**arange(11)) # roughly the frequencies we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basef = 20\n",
    "t = linspace(0,1,SR)\n",
    "sounds = zeros(1*SR)\n",
    "for f in basef*(2**arange(11)):\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds += sound\n",
    "display(Audio(data=sounds, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Wrap that in a function that takes base frequency as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alloctaves(basef,dur=1):\n",
    "    t = linspace(0,dur,int(dur*SR))\n",
    "    sounds = zeros(int(dur*SR))\n",
    "    for f in basef*(2**arange(11)):\n",
    "        sound = np.sin(2*pi*f*t)\n",
    "        sounds += sound\n",
    "    return sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=alloctaves(23), rate=SR)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispoct(f):\n",
    "    display(Audio(data=alloctaves(f), rate=SR)) \n",
    "v = interactive(dispoct, f=(20,40))\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE** Can you make a sequence of three shepard tones with base frequencies 20, 21 and 22 Hz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "for f in range(20,40,1):\n",
    "    sound = alloctaves(f,.25)\n",
    "    sounds.append(sound)\n",
    "    sounds.append(zeros(int(.05*SR)))\n",
    "signal = concatenate(sounds)\n",
    "signal = concatenate([signal,signal,signal,signal])\n",
    "display(Audio(data=signal, rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Shepard tones! https://en.wikipedia.org/wiki/Shepard_tone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = alloctaves(20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we find what frequencies were part of this sound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's where Fourier analysis comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourier Transform allows us to write any signal as a combination of pure sine waves. So it's doing the inverse of what we've been doing so far, namely combining pure sound waves into more complex sounds.\n",
    "\n",
    "The human ear also does something similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://4d6619e6-a-62cb3a1a-s-sites.googlegroups.com/site/jayanthinyswebsite/workshops/different%20aspects%20of%20organ%20of%20Corti.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bunch of detail in terms of math that is not too important here. What is important is the idea that you have a signal, and then it splits it into the various frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourierTransform = np.fft.fft(sound)/len(sound)           # Normalize amplitude\n",
    "fourierTransform = fourierTransform[range(int(len(sound)/2))] # Exclude sampling frequency\n",
    "tpCount     = len(sound)\n",
    "values      = np.arange(int(tpCount/2))\n",
    "timePeriod  = tpCount/SR\n",
    "frequencies = values/timePeriod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(frequencies, abs(fourierTransform))\n",
    "xlim(0,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the amplitude too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 440\n",
    "f2 = 660\n",
    "t = linspace(0,1,SR)\n",
    "sound = np.sin(2*pi*f1*t)+.5*np.sin(2*pi*f2*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourierTransform = np.fft.fft(sound)/len(sound)           # Normalize amplitude\n",
    "fourierTransform = fourierTransform[range(int(len(sound)/2))] # Exclude sampling frequency\n",
    "tpCount     = len(sound)\n",
    "values      = np.arange(int(tpCount/2))\n",
    "timePeriod  = tpCount/SR\n",
    "frequencies = values/timePeriod\n",
    "plot(frequencies, abs(fourierTransform))\n",
    "xlim(400,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://www.nti-audio.com/portals/0/pic/news/FFT-Time-Frequency-View-540.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []\n",
    "for f in [440,550,660,880,660,550,440]:\n",
    "    sound = np.sin(2*pi*f*t)\n",
    "    sounds.append(sound)\n",
    "data = concatenate(sounds)\n",
    "#signal = concatenate([signal])\n",
    "display(Audio(data=data, rate=SR))\n",
    "\n",
    "specgram(data,Fs=SR) \n",
    "ylabel('Frequency [Hz]')\n",
    "xlabel('Time [sec]')\n",
    "ylim(0,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt,data = scipy.io.wavfile.read('youare.wav') # source https://www.101soundboards.com\n",
    "display(Audio(data=data, rate=rt))\n",
    "specgram(data,Fs=rt) \n",
    "ylabel('Frequency [Hz]')\n",
    "xlabel('Time [sec]')\n",
    "ylim(0,15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Simple experiment: mapping positions to sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "van Vugt & Ostry \"audiomotor\" paradigm.\n",
    "\n",
    "http://www.psych.mcgill.ca/labs/mcl/pdf/jocn_a_01204.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://pbs.twimg.com/media/EHFzGNGXkAEzcv2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simplified mapping between position and sound:\n",
    "def angle2sound(angle):\n",
    "    # Angle in degrees, between 0 and 180 degrees\n",
    "    f1 = 400+2*angle\n",
    "    f2 = 1600-2*angle\n",
    "    sound = np.sin(2*pi*f1*t)+np.sin(2*pi*f2*t)\n",
    "    return sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=angle2sound(0),rate=SR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an interface\n",
    "\n",
    "Buttons, sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_next = ipywidgets.Button(description=\"Choose next target\")\n",
    "response = ipywidgets.IntSlider(value=90,min=0,max=180,step=1,\n",
    "                                description='What angle do you think corresponds to that sound?')\n",
    "button_respond = ipywidgets.Button(description=\"Select response\")\n",
    "display(button_next,response,button_respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {}\n",
    "record[\"target_angle\"] = 180*random.random()\n",
    "\n",
    "def select_target(e):\n",
    "    snd = angle2sound(record[\"target_angle\"])\n",
    "    clear_output()\n",
    "    display(ipywidgets.Label(value=\"This is your target sound:\"))\n",
    "    display(Audio(data=snd,rate=SR))\n",
    "    # add buttons for responding\n",
    "    display(response)\n",
    "    display(button_respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_next.on_click(select_target)\n",
    "display(button_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_response(e):\n",
    "    val = response.value\n",
    "    # Give the feedback sound\n",
    "    snd = angle2sound(val)\n",
    "    clear_output()\n",
    "    display(ipywidgets.Label(value=\"This is your feedback sound for an angle of \"+str(val)))\n",
    "    display(Audio(data=snd,rate=SR))\n",
    "    display(button_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_respond.on_click(register_response)\n",
    "display(button_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But so far we don't keep a record of the subject's performance.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = {'trials':[]}\n",
    "record[\"target_angle\"] = 180*random.random()\n",
    "\n",
    "def register_response(e):\n",
    "    val = response.value\n",
    "    record[\"trials\"].append({'target_angle':record[\"target_angle\"],\n",
    "                            'response_angle':val})\n",
    "    # Give the feedback sound\n",
    "    snd = angle2sound(val)\n",
    "    clear_output()\n",
    "    display(ipywidgets.Label(value=\"This is your feedback sound for an angle of \"+str(val)))\n",
    "    display(Audio(data=snd,rate=SR))\n",
    "    display(button_next)\n",
    "    \n",
    "button_respond.on_click(register_response)\n",
    "display(button_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record[\"trials\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = record['trials']\n",
    "for trial in trials:\n",
    "    trial['error']=trial['target_angle']-trial['response_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ trial['error'] for trial in trials ]\n",
    "plot(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
